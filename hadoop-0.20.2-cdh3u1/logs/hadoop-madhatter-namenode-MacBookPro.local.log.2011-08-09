2011-08-09 21:07:00,883 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MacBookPro.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-09 21:07:01,444 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 21:07:01,446 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 21:07:01,492 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-09 21:07:01,492 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-09 21:07:01,492 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-09 21:07:01,493 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-09 21:07:01,554 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:117)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:237)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.fs.DF.getFilesystem(DF.java:63)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.addDirsToCheck(NameNodeResourceChecker.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:327)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)
2011-08-09 21:07:01,558 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.close(FSNamesystem.java:560)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:330)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)

2011-08-09 21:07:01,559 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at MacBookPro.local/192.168.0.100
************************************************************/
2011-08-09 21:14:20,753 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MacBookPro.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-09 21:14:20,962 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 21:14:20,965 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 21:14:20,992 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-09 21:14:20,992 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-09 21:14:20,992 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-09 21:14:20,992 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-09 21:14:21,037 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:117)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:237)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.fs.DF.getFilesystem(DF.java:63)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.addDirsToCheck(NameNodeResourceChecker.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:327)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)
2011-08-09 21:14:21,041 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.close(FSNamesystem.java:560)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:330)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)

2011-08-09 21:14:21,043 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at MacBookPro.local/192.168.0.100
************************************************************/
2011-08-09 21:14:50,457 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MacBookPro.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-09 21:14:50,650 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 21:14:50,652 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 21:14:50,680 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-09 21:14:50,680 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-09 21:14:50,680 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-09 21:14:50,680 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-09 21:14:50,724 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:117)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:237)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.fs.DF.getFilesystem(DF.java:63)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.addDirsToCheck(NameNodeResourceChecker.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:327)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)
2011-08-09 21:14:50,728 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.close(FSNamesystem.java:560)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:330)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)

2011-08-09 21:14:50,729 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at MacBookPro.local/192.168.0.100
************************************************************/
2011-08-09 21:19:38,598 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MacBookPro.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-09 21:19:38,810 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 21:19:38,813 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 21:19:38,839 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-09 21:19:38,839 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-09 21:19:38,839 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-09 21:19:38,839 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-09 21:19:38,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=madhatter
2011-08-09 21:19:38,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2011-08-09 21:19:38,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-08-09 21:19:38,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-08-09 21:19:38,922 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2011-08-09 21:19:39,178 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 21:19:39,243 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2011-08-09 21:19:39,248 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2011-08-09 21:19:39,248 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 loaded in 0 seconds.
2011-08-09 21:19:39,249 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /Users/madhatter/CDH3/hadoop-cache/madhatter/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 21:19:39,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 saved in 0 seconds.
2011-08-09 21:19:39,360 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 saved in 0 seconds.
2011-08-09 21:19:39,380 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 476 msecs
2011-08-09 21:19:39,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2011-08-09 21:19:39,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2011-08-09 21:19:39,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2011-08-09 21:19:39,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2011-08-09 21:19:39,400 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2011-08-09 21:19:39,401 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 21:19:39,401 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 21:19:39,415 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-08-09 21:19:39,444 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2011-08-09 21:19:39,446 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-09 21:19:39,448 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-09 21:19:39,469 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2011-08-09 21:19:39,581 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-09 21:19:39,651 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 21:19:39,690 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2011-08-09 21:19:39,692 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2011-08-09 21:19:39,692 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2011-08-09 21:19:39,692 INFO org.mortbay.log: jetty-6.1.26
2011-08-09 21:19:40,242 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2011-08-09 21:19:40,243 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2011-08-09 21:19:40,243 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2011-08-09 21:19:40,244 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2011-08-09 21:19:40,251 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2011-08-09 21:19:40,252 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2011-08-09 21:19:40,252 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2011-08-09 21:19:40,252 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2011-08-09 21:19:40,252 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2011-08-09 21:19:40,253 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2011-08-09 21:19:40,253 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2011-08-09 21:19:40,253 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2011-08-09 21:19:40,262 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2011-08-09 21:19:40,263 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2011-08-09 21:19:41,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-257746229-192.168.0.100-50010-1312917581970
2011-08-09 21:19:41,976 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2011-08-09 21:21:21,475 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at MacBookPro.local/192.168.0.100
************************************************************/
2011-08-09 21:24:30,394 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MacBookPro.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-09 21:24:30,601 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 21:24:30,604 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 21:24:30,630 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-09 21:24:30,631 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-09 21:24:30,631 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-09 21:24:30,631 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-09 21:24:30,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=madhatter
2011-08-09 21:24:30,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2011-08-09 21:24:30,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-08-09 21:24:30,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-08-09 21:24:30,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2011-08-09 21:24:30,978 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 21:24:31,031 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2011-08-09 21:24:31,036 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2011-08-09 21:24:31,037 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 loaded in 0 seconds.
2011-08-09 21:24:31,038 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /Users/madhatter/CDH3/hadoop-cache/madhatter/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 21:24:31,039 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 saved in 0 seconds.
2011-08-09 21:24:31,150 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 saved in 0 seconds.
2011-08-09 21:24:31,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 471 msecs
2011-08-09 21:24:31,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2011-08-09 21:24:31,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2011-08-09 21:24:31,184 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2011-08-09 21:24:31,184 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2011-08-09 21:24:31,184 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2011-08-09 21:24:31,184 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 21:24:31,184 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 21:24:31,204 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-08-09 21:24:31,230 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2011-08-09 21:24:31,233 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-09 21:24:31,234 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-09 21:24:31,239 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2011-08-09 21:24:31,338 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-09 21:24:31,467 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 21:24:31,481 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2011-08-09 21:24:31,485 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2011-08-09 21:24:31,486 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2011-08-09 21:24:31,486 INFO org.mortbay.log: jetty-6.1.26
2011-08-09 21:24:31,991 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2011-08-09 21:24:31,991 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2011-08-09 21:24:32,030 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2011-08-09 21:24:32,031 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2011-08-09 21:24:32,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2011-08-09 21:24:32,034 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2011-08-09 21:24:32,034 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2011-08-09 21:24:32,034 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2011-08-09 21:24:32,035 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2011-08-09 21:24:32,035 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2011-08-09 21:24:32,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2011-08-09 21:24:32,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2011-08-09 21:24:32,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2011-08-09 21:24:32,037 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2011-08-09 21:24:34,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-257746229-192.168.0.100-50010-1312917581970
2011-08-09 21:24:34,074 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2011-08-09 21:24:37,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /Users/madhatter/CDH3/hadoop-cache/madhatter/mapred/system/jobtracker.info. blk_4611026343218451507_1001
2011-08-09 21:24:38,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_4611026343218451507_1001 size 4
2011-08-09 21:24:38,156 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /Users/madhatter/CDH3/hadoop-cache/madhatter/mapred/system/jobtracker.info from client DFSClient_2003993302
2011-08-09 21:24:38,157 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /Users/madhatter/CDH3/hadoop-cache/madhatter/mapred/system/jobtracker.info is closed by DFSClient_2003993302
2011-08-09 21:29:35,534 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2011-08-09 21:29:35,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 12 Total time for transactions(ms): 2Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 11 
2011-08-09 21:29:36,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 127.0.0.1
2011-08-09 21:29:36,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 
2011-08-09 21:30:33,054 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at MacBookPro.local/192.168.0.100
************************************************************/
