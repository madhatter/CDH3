2011-08-10 08:25:28,407 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = nothing/172.20.10.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-10 08:25:28,654 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-10 08:25:28,657 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-10 08:25:28,683 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-10 08:25:28,683 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-10 08:25:28,683 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-10 08:25:28,683 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-10 08:25:28,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=madhatter
2011-08-10 08:25:28,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2011-08-10 08:25:28,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-08-10 08:25:28,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-08-10 08:25:28,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2011-08-10 08:25:29,020 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-10 08:25:29,068 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 9
2011-08-10 08:25:29,076 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2011-08-10 08:25:29,076 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 995 loaded in 0 seconds.
2011-08-10 08:25:29,076 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /Users/madhatter/CDH3/hadoop-cache/madhatter/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-10 08:25:29,078 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 995 saved in 0 seconds.
2011-08-10 08:25:29,189 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 995 saved in 0 seconds.
2011-08-10 08:25:29,207 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 460 msecs
2011-08-10 08:25:29,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1
2011-08-10 08:25:29,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2011-08-10 08:25:29,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 1
2011-08-10 08:25:29,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2011-08-10 08:25:29,230 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2011-08-10 08:25:29,230 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2011-08-10 08:25:29,230 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 1 blocks
2011-08-10 08:25:29,238 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-08-10 08:25:29,271 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2011-08-10 08:25:29,273 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-10 08:25:29,274 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-10 08:25:29,277 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2011-08-10 08:25:29,558 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-10 08:25:29,612 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-10 08:25:29,651 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2011-08-10 08:25:29,652 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2011-08-10 08:25:29,652 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2011-08-10 08:25:29,653 INFO org.mortbay.log: jetty-6.1.26
2011-08-10 08:25:30,169 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2011-08-10 08:25:30,170 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2011-08-10 08:25:30,170 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2011-08-10 08:25:30,170 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2011-08-10 08:25:30,171 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2011-08-10 08:25:30,172 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2011-08-10 08:25:30,172 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2011-08-10 08:25:30,172 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2011-08-10 08:25:30,172 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2011-08-10 08:25:30,173 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2011-08-10 08:25:30,173 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2011-08-10 08:25:30,173 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2011-08-10 08:25:30,173 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2011-08-10 08:25:30,173 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2011-08-10 08:25:32,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-257746229-192.168.0.100-50010-1312917581970
2011-08-10 08:25:32,279 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2011-08-10 08:25:32,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_4611026343218451507_1001 size 4
2011-08-10 08:25:35,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4611026343218451507 is added to invalidSet of 127.0.0.1:50010
2011-08-10 08:25:35,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /Users/madhatter/CDH3/hadoop-cache/madhatter/mapred/system/jobtracker.info. blk_15571224085505229_1002
2011-08-10 08:25:35,848 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_15571224085505229_1002 size 4
2011-08-10 08:25:35,884 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /Users/madhatter/CDH3/hadoop-cache/madhatter/mapred/system/jobtracker.info from client DFSClient_-1935482695
2011-08-10 08:25:35,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /Users/madhatter/CDH3/hadoop-cache/madhatter/mapred/system/jobtracker.info is closed by DFSClient_-1935482695
2011-08-10 08:25:38,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 127.0.0.1:50010 to delete  blk_4611026343218451507_1001
2011-08-10 08:27:20,003 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:66)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:43)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1034)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5069)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5052)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1945)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:805)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1127)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)
2011-08-10 08:27:41,774 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at nothing/172.20.10.2
************************************************************/
2011-08-10 08:28:59,721 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = nothing/172.20.10.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-10 08:28:59,936 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-10 08:28:59,939 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-10 08:28:59,965 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-10 08:28:59,965 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-10 08:28:59,965 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-10 08:28:59,965 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-10 08:29:00,011 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:117)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:237)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.fs.DF.getFilesystem(DF.java:63)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.addDirsToCheck(NameNodeResourceChecker.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:327)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)
2011-08-10 08:29:00,015 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.close(FSNamesystem.java:560)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:330)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1224)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)

2011-08-10 08:29:00,018 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at nothing/172.20.10.2
************************************************************/
2011-08-10 08:31:03,596 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = nothing/172.20.10.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u1
STARTUP_MSG:   build = file:///var/lib/jenkins/workspace/CDH3u1-CentOS-Hadoop-Tarball/hadoop20/hadoop-0.20.2-cdh3u1 -r bdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638; compiled by 'jenkins' on Mon Jul 18 12:08:54 PDT 2011
************************************************************/
2011-08-10 08:31:03,804 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-10 08:31:03,807 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-10 08:31:03,833 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-08-10 08:31:03,833 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-08-10 08:31:03,833 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-08-10 08:31:03,833 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-08-10 08:31:03,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=madhatter
2011-08-10 08:31:03,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2011-08-10 08:31:03,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-08-10 08:31:03,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-08-10 08:31:03,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2011-08-10 08:31:04,157 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-10 08:31:04,216 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2011-08-10 08:31:04,221 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2011-08-10 08:31:04,221 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 loaded in 0 seconds.
2011-08-10 08:31:04,221 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /Users/madhatter/CDH3/hadoop-cache/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-10 08:31:04,223 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 saved in 0 seconds.
2011-08-10 08:31:04,341 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 115 saved in 0 seconds.
2011-08-10 08:31:04,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 492 msecs
2011-08-10 08:31:04,402 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2011-08-10 08:31:04,402 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2011-08-10 08:31:04,402 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2011-08-10 08:31:04,402 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2011-08-10 08:31:04,402 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
2011-08-10 08:31:04,403 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2011-08-10 08:31:04,403 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2011-08-10 08:31:04,412 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-08-10 08:31:04,442 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2011-08-10 08:31:04,444 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-10 08:31:04,446 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-08-10 08:31:04,448 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2011-08-10 08:31:04,528 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-10 08:31:04,588 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-10 08:31:04,599 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2011-08-10 08:31:04,601 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2011-08-10 08:31:04,601 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2011-08-10 08:31:04,601 INFO org.mortbay.log: jetty-6.1.26
2011-08-10 08:31:05,159 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2011-08-10 08:31:05,160 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2011-08-10 08:31:05,160 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2011-08-10 08:31:05,160 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2011-08-10 08:31:05,161 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2011-08-10 08:31:05,162 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2011-08-10 08:31:05,162 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2011-08-10 08:31:05,162 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2011-08-10 08:31:05,163 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2011-08-10 08:31:05,163 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2011-08-10 08:31:05,163 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2011-08-10 08:31:05,163 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2011-08-10 08:31:05,164 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2011-08-10 08:31:05,164 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2011-08-10 08:31:07,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-1179262424-172.20.10.2-50010-1312957867331
2011-08-10 08:31:07,339 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2011-08-10 08:31:11,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /Users/madhatter/CDH3/hadoop-cache/mapred/system/jobtracker.info. blk_-5396185410863926075_1001
2011-08-10 08:31:11,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_-5396185410863926075_1001 size 4
2011-08-10 08:31:11,167 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /Users/madhatter/CDH3/hadoop-cache/mapred/system/jobtracker.info from client DFSClient_-172964830
2011-08-10 08:31:11,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /Users/madhatter/CDH3/hadoop-cache/mapred/system/jobtracker.info is closed by DFSClient_-172964830
2011-08-10 08:31:18,647 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:66)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:43)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1034)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5069)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5052)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1945)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:805)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1127)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)
2011-08-10 08:31:31,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at nothing/172.20.10.2
************************************************************/
